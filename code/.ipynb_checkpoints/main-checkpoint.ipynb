{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"train_param\";\n",
    "eta = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMP5212 Programming Project 2\n",
      "Tensor(\"placeholders_6/img:0\", shape=(?, 28, 28), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUM_LABELS = 47\n",
    "rnd = np.random.RandomState(123)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Following functions are helper functions that you can feel free to change\n",
    "def convert_image_data_to_float(image_raw):\n",
    "    img_float = tf.expand_dims(tf.cast(image_raw, tf.float32) / 255, axis=-1)\n",
    "    return img_float\n",
    "\n",
    "\n",
    "def visualize_ae(i, x, features, reconstructed_image):\n",
    "    '''\n",
    "    This might be helpful for visualizing your autoencoder outputs\n",
    "    :param i: index\n",
    "    :param x: original data\n",
    "    :param features: feature maps\n",
    "    :param reconstructed_image: autoencoder output\n",
    "    :return:\n",
    "    '''\n",
    "    plt.figure(0)\n",
    "    plt.imshow(x[i, :, :], cmap=\"gray\")\n",
    "    plt.figure(1)\n",
    "    plt.imshow(reconstructed_image[i, :, :, 0], cmap=\"gray\")\n",
    "    plt.figure(2)\n",
    "    plt.imshow(np.reshape(features[i, :, :, :], (7, -1), order=\"F\"), cmap=\"gray\",)\n",
    "\n",
    "\n",
    "def cnn_model(placeholder_x, placeholder_y, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    with tf.variable_scope(\"cnn\") as scope:\n",
    "        # input layer\n",
    "        img_float = convert_image_data_to_float(placeholder_x)     \n",
    "        # TODO: batch_size\n",
    "        img_flattened = tf.reshape(img_float,[-1,np.prod(placeholder_x.shape[1:])])\n",
    "        \n",
    "        # convolutional layer 1\n",
    "        conv1 = tf.layers.conv2d(\n",
    "            inputs=img_flattened,\n",
    "            filters=32,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        # pooling layer 1\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "        \n",
    "        #convolutional layer 2\n",
    "        conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=32,\n",
    "            kernel_size=[5, 5],\n",
    "            strides=2,\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        # pooling layer 2\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)        \n",
    "        \n",
    "        #convolutional layer 3\n",
    "        conv3 = tf.layers.conv2d(\n",
    "            inputs=pool2,\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        # pooling layer 3\n",
    "        pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)                \n",
    "        \n",
    "        #convolutional layer 4\n",
    "        conv4 = tf.layers.conv2d(\n",
    "            inputs=pool3,\n",
    "            filters=64,\n",
    "            kernel_size=[5, 5],\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu)\n",
    "        # pooling layer 4\n",
    "        pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=2)            \n",
    "        \n",
    "        # dense Layer\n",
    "        dense = tf.layers.dense(inputs=pool4, units=1024, activation=tf.nn.relu)\n",
    "        \n",
    "        # output layer\n",
    "        dropout = tf.layers.dropout(\n",
    "            inputs=dense,\n",
    "            rate=0.4,\n",
    "            training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        \n",
    "        # logits Layer\n",
    "        logits = tf.layers.dense(inputs=dropout, units=2)        \n",
    "        \n",
    "        predictions = {\n",
    "            # Generate predictions (for PREDICT and EVAL mode)\n",
    "            \"classes\": tf.argmax(input=dropout, axis=1),\n",
    "            # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "            # `logging_hook`.\n",
    "            \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "        }\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(labels=placeholder_y, logits=logits) \n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate=eta)\n",
    "            train_op = optimizer.minimize(\n",
    "                loss=loss,\n",
    "                global_step=tf.train.get_global_step())\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)        \n",
    "        \n",
    "        # Add evaluation metrics (for EVAL mode)\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\": tf.metrics.accuracy(\n",
    "                labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)        \n",
    "        \n",
    "#         loss = tf.losses.sparse_softmax_cross_entropy(labels=placeholder_y, logits=logits)        \n",
    "        \n",
    "#         weight = tf.get_variable(\"fc_weight\",shape=(img_flattened.shape[1],NUM_LABELS),\n",
    "#                                  initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        \n",
    "#         logits = tf.matmul(img_flattened, weight)\n",
    "\n",
    "#         loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "#             labels=placeholder_y, logits=logits)\n",
    "\n",
    "#         # gradient decent algorithm\n",
    "#         params = [weight]\n",
    "#         learning_rate = 0.001\n",
    "#         grad = tf.gradients(loss, weight)[0]\n",
    "#         train_op = tf.assign_add(weight, -learning_rate * grad)\n",
    "\n",
    "    return params, train_op\n",
    "\n",
    "\n",
    "CNN_MODEL_PATH = \"./cnn_model\"\n",
    "\n",
    "# Major interfaces\n",
    "# placeholder_x: image, placeholder_y: label\n",
    "def train_cnn(x, y, placeholder_x, placeholder_y):\n",
    "    emnist_classifier = tf.estimator.Estimator(model=cnn_model, model_dir=CNN_MODEL_PATH);\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": placeholder_x},\n",
    "        y=placeholder_y,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "\n",
    "      mnist_classifier.train(\n",
    "          input_fn=train_input_fn,\n",
    "          steps=20000,\n",
    "          hooks=[logging_hook])\n",
    "\n",
    "def test_cnn(x, y, placeholder_x, placeholder_y):\n",
    "    # TODO: implement CNN testing\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "          x={\"x\": placeholder_x},\n",
    "          y=placeholder_y,\n",
    "          num_epochs=1,\n",
    "          shuffle=False)\n",
    "    test_result_accuracy = mnist_classifier.evaluate(input_fn=test_input_fn)\n",
    "    print(test_result_accuracy)  \n",
    "    \n",
    "#     eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "#           x={\"x\": eval_data},\n",
    "#           y=eval_labels,\n",
    "#           num_epochs=1,\n",
    "#           shuffle=False)\n",
    "#     eval_result_accuracy = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "#     print(eval_result_accuracy)    \n",
    "\n",
    "    return test_result_accuracy\n",
    "\n",
    "\n",
    "def train_ae(x, placeholder_x):\n",
    "    # TODO: implement autoencoder training\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def evaluate_ae(x,placeholder_x):\n",
    "    # TODO: evaluate your autoencoder\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--description\", default=\"COMP5212 Programming Project 2\", \n",
    "                        help=\"increase output verbosity\")\n",
    "    parser.add_argument('--task', default=\"train\", type=str,\n",
    "                        help='Select the task, train_cnn, test_cnn, '\n",
    "                             'train_ae, evaluate_ae, ')\n",
    "    parser.add_argument('--datapath',default=\"../dataset\",type=str, required=False,\n",
    "                        help='Select the path to the data directory')\n",
    "    args = parser.parse_args(args=[])\n",
    "    print(args.description)\n",
    "    datapath = args.datapath\n",
    "\n",
    "# TODO:     \n",
    "    with tf.variable_scope(\"placeholders\"):\n",
    "        img_var = tf.placeholder(tf.uint8, shape=(None, 28, 28), name=\"img\")\n",
    "        label_var = tf.placeholder(tf.int32, shape=(None,), name=\"true_label\")\n",
    "\n",
    "    if args.task == \"train_cnn\":\n",
    "        file_train = np.load(datapath+\"/data_classifier_train.npz\")\n",
    "        x_train = file_train[\"x_train\"]\n",
    "        y_train = file_train[\"y_train\"]\n",
    "        train_cnn(x_train, y_train, img_var, label_var)\n",
    "    elif args.task == \"test_cnn\":\n",
    "        file_test = np.load(datapath+\"/data_classifier_test.npz\")\n",
    "        x_test = file_test[\"x_test\"]\n",
    "        y_test = file_test[\"y_test\"]\n",
    "        accuracy = test_cnn(x_test, y_test,img_var,label_var)\n",
    "        print(\"accuracy = {}\\n\".format(accuracy))\n",
    "    elif args.task == \"train_ae\":\n",
    "        file_unsupervised = np.load(datapath + \"/data_autoencoder_train.npz\")\n",
    "        x_ae_train = file_unsupervised[\"x_ae_train\"]\n",
    "        train_ae(x_ae_train, img_var)\n",
    "    elif args.task == \"evaluate_ae\":\n",
    "        file_unsupervised = np.load(datapath + \"/data_autoencoder_eval.npz\")\n",
    "        x_ae_eval = file_unsupervised[\"x_ae_eval\"]\n",
    "        evaluate_ae(x_ae_eval, img_var)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.variable_scope(\"placeholders\"):\n",
    "    a = 1\n",
    "    print(a)\n",
    "with tf.variable_scope(\"test\"):\n",
    "    a = 2\n",
    "    print(a)\n",
    "with tf.variable_scope(\"placeholders\"):\n",
    "    print(a)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
